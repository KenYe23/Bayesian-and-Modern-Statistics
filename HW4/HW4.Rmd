---
---
---

STA360 Homework 4 (Ken Ye)

```{r}
library(latex2exp)
set.seed(0)
```

#1

a)  

```{r}
# tumor count data
y_A <- c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)
y_B <- c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)
a_A <- 120
b_A <- 10
a_B <- 12
b_B <- 1
n_A <- length(y_A)
sy_A <- sum(y_A) 
n_B <- length(y_B) 
sy_B <- sum(y_B) 
```

```{r}
# monte carlo
t_A.mc <- NULL
for (s in 1:1000){
  theta_A.mc <- rgamma(1, a_A + sy_A, b_A + n_A)
  y_A.mc <- rpois(10,theta_A.mc)
  t <- mean(y_A.mc) / sd(y_A.mc)
  t_A.mc <- c(t_A.mc,t)
}
```

```{r}
# observed value of t_A
obs_t_A = mean(y_A) / sd(y_A)
print(obs_t_A)
```

```{r}
# plot
hist(t_A.mc,
     main = TeX('$Distribution \\ of \\ t^{(s)}$'),
     xlab = TeX('$t^{(s)}$'),
     ylab = TeX('$Frequency$'))
abline(v = obs_t_A)
```

According to the histogram, the observed value of the this t statistic (sample average divided by sample standard deviation) lies at the center of the distribution (high probability of getting a value as extreme) produced by our Monte Carlo simulation. Therefore, the Poisson model might be a good fit for these data (population A).

b)  

```{r}
# monte carlo
t_B.mc <- NULL
for (s in 1:1000){
  theta_B.mc <- rgamma(1, a_B + sy_B, b_B + n_B)
  y_B.mc <- rpois(10,theta_B.mc)
  t <- mean(y_B.mc) / sd(y_B.mc)
  t_B.mc <- c(t_B.mc,t)
}
```

```{r}
# observed value of t_A
obs_t_B = mean(y_B) / sd(y_B)
print(obs_t_B)
```

```{r}
# plot
hist(t_B.mc,
     main = TeX('$Distribution \\ of \\ t^{(s)}$'),
     xlab = TeX('$t^{(s)}$'),
     ylab = TeX('$Frequency$'))
abline(v = obs_t_B)
```

According to the histogram, the observed value of the this t statistic (sample average divided by sample standard deviation) lies at the far right tail of the distribution (low probability of getting a value as extreme) produced by our Monte Carlo simulation. Therefore, the Poisson model might not be a good fit for these data (population B).

\newpage

#2

a)  

```{r}
# posteior p(theta | y) calculated in hw3
posterior <- function (theta) {
  sy <- 2
  n <- 5
  m1 <- 3 * theta^(sy + 1) * (1 - theta)^(n - sy + 7)
  m2 <- theta^(sy + 7) * (1 - theta)^(n - sy + 1)
  # constant <- 3 * beta (sy + 2, n - sy + 8) + beta (sy + 8 , n - sy + 2)
  return (m1 + m2)
}
```

```{r}
# plot
thetas <- seq(from = 0, to = 1, by = 0.001)
post <- posterior(thetas)
normal_c <- 1/sum(post) # to make integral equal to 1
post_n <- post*normal_c
plot (thetas, post_n, type = "l",
     main = TeX("Posterior Distribution of \\theta"),
     xlab = TeX("\\theta"),
     ylab = TeX('$PDF(\\theta)$'))
```

```{r}
# 95% CI for theta
lower = thetas[which(cumsum(post_n) >= 0.025)][1]
upper = thetas[which(cumsum(post_n) >= 0.975)][1]
print(lower)
print(upper)
```

A 95% quantile-based posterior confidence interval for $\theta$ is (0.087, 0.766).

b\.

From homework 3, we calculated that:

$$
p1 = beta(\Sigma_{i=1}^{n} y_i + 2, n-\Sigma_{i=1}^{n} y_i+8)
$$

and

$$
p2 = beta(\Sigma_{i=1}^{n} y_i + 8, n-\Sigma_{i=1}^{n} y_i+2)
$$

```{r}
# monte carlo approximation of the posterior distribution p(theta|y)
sy <- 2
n <- 5
w <- 3 * beta(sy + 2, n - sy + 8) / 
  (3 * beta(sy + 2, n - sy + 8) + beta(sy + 8, n - sy + 2))

sim <- c()

for (i in 1: 1000){
  coin <- rbinom(n = 1, size = 1, prob = w)
  if (coin == 1) {
    sim <- c(sim, rbeta(1, sy + 2, n - sy + 8))
  } else {
    sim <- c(sim, rbeta(1, sy + 8, n - sy + 2))
  }
}
```

```{r}
# plot
hist(sim, 
     main = TeX("MC Approximated Posterior Distribution of \\theta"),
     xlab = TeX("\\theta"), 
     ylab = "Frequency")
```

The distribution of the MC approximated posterior $\theta$ resembles the one obtained in part a.

```{r}
# confidence interval
quantile(sim, c(0.025, 0.975))
```

The 95% quantile-based confidence interval for MC approximated posterior distribution of $\theta$ is (0.083, 0.793), which is fairly similar to the interval found in part a, which is (0.087, 0.766).

\newpage

#4

a)  

```{r}
# data
School1 <- c(2.11, 9.75, 13.88, 11.3, 8.93, 15.66, 16.38, 4.54, 8.86, 11.94, 12.47, 11.11, 11.65, 14.53, 9.61, 7.38, 3.34, 9.06, 9.45, 5.98, 7.44, 8.5, 1.55, 11.45, 9.73)

School2 <- c(0.29, 1.13, 6.52, 11.72, 6.54, 5.63, 14.59, 11.74, 9.12, 9.43, 10.64, 12.28, 9.5, 0.63, 15.35, 5.31, 8.49, 3.04, 3.77, 6.22, 2.14, 6.58, 1.11)

School3 <- c(4.33, 7.77, 4.15, 5.64, 7.69, 5.04, 10.01, 13.43, 13.63, 9.9, 5.72, 5.16, 4.33, 12.9, 11.27, 6.05, 0.95, 6.02, 12.22, 12.85)
```

```{r}
# prior
mu0 <- 5
s20 <- 4
k0 <- 1
nu0 <- 2
n1 <- length(School1)
n2 <- length(School2)
n3 <- length(School3)
ybar1 <- mean(School1)
ybar2 <- mean(School2)
ybar3 <- mean(School3)
s21 <- var(School1)
s22 <- var(School2)
s23 <- var(School3)
```

```{r}
# posterior
kn1 <- k0 + n1
kn2 <- k0 + n2
kn3 <- k0 + n3
nun1 <- nu0 + n1
nun2 <- nu0 + n2
nun3 <- nu0 + n3
mun1 <- (k0 * mu0 + n1 * ybar1) / kn1
mun2 <- (k0 * mu0 + n2 * ybar2) / kn2
mun3 <- (k0 * mu0 + n3 * ybar3) / kn3
s2n1 <- (nu0 * s20 + (n1 - 1) * s21 + k0 * n1 * (ybar1 - mu0)^2 / kn1) / nun1
s2n2 <- (nu0 * s20 + (n2 - 1) * s22 + k0 * n2 * (ybar2 - mu0)^2 / kn2) / nun2
s2n3 <- (nu0 * s20 + (n1 - 1) * s23 + k0 * n3 * (ybar3 - mu0)^2 / kn3) / nun3
```

```{r}
mc_size = 10000
```

```{r}
# school 1
s21.mc <- 1/rgamma(mc_size, nun1/2, nun1/2*s2n1)
theta1.mc <- rnorm(mc_size, mun1, sqrt(s21.mc/kn1))
print(paste0('The posterior mean of School 1\' mean (theta) is ', mean(theta1.mc)))
theta1.ci <- quantile(theta1.mc, c(0.025, 0.975))
sn1.ci <- quantile(s21.mc, c(0.025, 0.975))
print('The posterior 95% confidence interval of School 1\' mean (theta) is:')
print(theta1.ci)
print('The posterior 95% confidence interval of School 1\' standard deviation is:')
print(sn1.ci)
```

```{r}
# school 2
s22.mc <- 1/rgamma(mc_size, nun2/2, nun2/2*s2n2)
theta2.mc <- rnorm(mc_size, mun2, sqrt(s22.mc/kn2))
print(paste0('The posterior mean of School 2\' mean (theta) is ', mean(theta2.mc)))
theta2.ci <- quantile(theta2.mc, c(0.025, 0.975))
sn2.ci <- quantile(s22.mc, c(0.025, 0.975))
print('The posterior 95% confidence interval of School 2\' mean (theta) is:')
print(theta2.ci)
print('The posterior 95% confidence interval of School 2\' standard deviation is:')
print(sn2.ci)
```

```{r}
# school 3
s23.mc <- 1/rgamma(mc_size, nun3/2, nun3/2*s2n3)
theta3.mc <- rnorm(mc_size, mun3, sqrt(s23.mc/kn3))
print(paste0('The posterior mean of School 3\' mean (theta) is ', mean(theta3.mc)))
theta3.ci <- quantile(theta3.mc, c(0.025, 0.975))
sn3.ci <- quantile(s23.mc, c(0.025, 0.975))
print('The posterior 95% confidence interval of School 3\' mean (theta) is:')
print(theta3.ci)
print('The posterior 95% confidence interval of School 3\' standard deviation is:')
print(sn3.ci)
```

b)  

```{r}
# theta1 < theta2 < theta3
count1 = 0

for(i in 1 : mc_size){
  if((theta1.mc[i] < theta2.mc[i]) & (theta2.mc[i] < theta3.mc[i])){
    count1 = count1 + 1
  }
}

prop1 =  count1 / mc_size
print(paste0('The posterior probability that theta1 < theta2 < theta3 is ', prop1))
```

```{r}
# theta2 < theta1 < theta3
count2 = 0

for(i in 1 : mc_size){
  if((theta2.mc[i] < theta1.mc[i]) & (theta1.mc[i] < theta3.mc[i])){
    count2 = count2 + 1
  }
}

prop2 =  count2 / mc_size
print(paste0('The posterior probability that theta2 < theta1 < theta3 is ', prop2))
```

```{r}
# theta1 < theta3 < theta2
count3 = 0

for(i in 1 : mc_size){
  if((theta1.mc[i] < theta3.mc[i]) & (theta3.mc[i] < theta2.mc[i])){
    count3 = count3 + 1
  }
}

prop3 =  count3 / mc_size
print(paste0('The posterior probability that theta1 < theta3 < theta2 is ', prop3))
```

```{r}
# theta3 < theta1 < theta2
count4 = 0

for(i in 1 : mc_size){
  if((theta3.mc[i] < theta1.mc[i]) & (theta1.mc[i] < theta2.mc[i])){
    count4 = count4 + 1
  }
}

prop4 =  count4 / mc_size
print(paste0('The posterior probability that theta3 < theta1 < theta2 is ', prop4))
```

```{r}
# theta2 < theta3 < theta1
count5 = 0

for(i in 1 : mc_size){
  if((theta2.mc[i] < theta3.mc[i]) & (theta3.mc[i] < theta1.mc[i])){
    count5 = count5 + 1
  }
}

prop5 =  count5 / mc_size
print(paste0('The posterior probability that theta2 < theta3 < theta1 is ', prop5))
```

```{r}
# theta3 < theta2 < theta1
count6 = 0

for(i in 1 : mc_size){
  if((theta3.mc[i] < theta2.mc[i]) & (theta2.mc[i] < theta1.mc[i])){
    count6 = count6 + 1
  }
}

prop6 =  count6 / mc_size
print(paste0('The posterior probability that theta3 < theta2 < theta1 is ', prop6))
```

c\.

```{r}
# take mc prediction samples
y1.mc <- rnorm(mc_size, mun1, sqrt(s2n1))
y2.mc <- rnorm(mc_size, mun2, sqrt(s2n2))
y3.mc <- rnorm(mc_size, mun3, sqrt(s2n3))
```

```{r}
# Y1 < Y2 < Y3
count1 = 0

for(i in 1 : mc_size){
  if((y1.mc[i] < y2.mc[i]) & (y2.mc[i] < y3.mc[i])){
    count1 = count1 + 1
  }
}

prop1 =  count1 / mc_size
print(paste0('The posterior probability that Y1 < Y2 < Y3 (prediction) is ', prop1))
```

```{r}
# Y1 < Y3 < Y2
count2 = 0

for(i in 1 : mc_size){
  if((y1.mc[i] < y3.mc[i]) & (y3.mc[i] < y2.mc[i])){
    count2 = count2 + 1
  }
}

prop2 =  count2 / mc_size
print(paste0('The posterior probability that Y1 < Y3 < Y2 (prediction) is ', prop2))
```

```{r}
# Y3 < Y2 < Y1
count3 = 0

for(i in 1 : mc_size){
  if((y3.mc[i] < y2.mc[i]) & (y2.mc[i] < y1.mc[i])){
    count3 = count3 + 1
  }
}

prop3 =  count3 / mc_size
print(paste0('The posterior probability that Y3 < Y2 < Y1 (prediction) is ', prop3))
```

```{r}
# Y2 < Y1 < Y3
count4 = 0

for(i in 1 : mc_size){
  if((y2.mc[i] < y1.mc[i]) & (y1.mc[i] < y3.mc[i])){
    count4 = count4 + 1
  }
}

prop4 =  count4 / mc_size
print(paste0('The posterior probability that Y2 < Y1 < Y3 (prediction) is ', prop4))
```

```{r}
# Y3 < Y1 < Y2
count5 = 0

for(i in 1 : mc_size){
  if((y3.mc[i] < y1.mc[i]) & (y1.mc[i] < y2.mc[i])){
    count5 = count5 + 1
  }
}

prop5 =  count5 / mc_size
print(paste0('The posterior probability that Y3 < Y1 < Y2 (prediction) is ', prop5))
```

```{r}
# Y2 < Y3 < Y1
count6 = 0

for(i in 1 : mc_size){
  if((y2.mc[i] < y3.mc[i]) & (y3.mc[i] < y1.mc[i])){
    count6 = count6 + 1
  }
}

prop6 =  count6 / mc_size
print(paste0('The posterior probability that Y2 < Y3 < Y1 (prediction) is ', prop6))
```

d\.

```{r}
# theta1 > both theta2 and theta3
count = 0

for(i in 1 : mc_size){
  if((theta1.mc[i] > theta2.mc[i]) & (theta1.mc[i] > theta3.mc[i])){
    count = count + 1
  }
}

prop =  count / mc_size
print(paste0('The posterior probability that theta1 > both theta2 and theta3 is ', prop))
```

```{r}
# Y1 > both Y2 and Y3
count = 0

for(i in 1 : mc_size){
  if((y1.mc[i] > y2.mc[i]) & (y1.mc[i] > y3.mc[i])){
    count = count + 1
  }
}

prop =  count / mc_size
print(paste0('The posterior probability that Y1 > both Y2 and Y3 (prediction) is ', prop))
```
